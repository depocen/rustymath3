# Markov Chain Monte Carlo Methods

```{r}

```
 http://statisticalrecipes.blogspot.com/2013/01/easy-introduction-to-markov-chains-in-r.html  
 http://st47s.com/Math154/Notes/compstat.html 
 https://www.econometrics-with-r.org/2-2-RSATDOSA.html
 
http://www.stats.ox.ac.uk/%7Enicholls/CompStats/  
 
 
## Introduction
### Law of Total Probability  

https://www.siue.edu/~jpailde/MCMC-Stat575-2016.html#stationary_distribution 
If events A1,…,Ak partition a sample space S into mutually exclusive and exhaustive nonempty events, then the states that the probability of an event B is
$$P(A)=\sum_{i} P(A \cap B_i)=\sum_{i} P(A | B_i) P(B_i). $$

For continuous random variables X and Y we have the distributional form  

$$f_{Y}(y)=\int_{-\infty}^{\infty}f_{Y|X=x}(y)f_{X}(x)dx.$$

For discrete random variables X and Y we can write the distributional form 

$$f_{Y}(y)=P(Y=y)=\sum_{x}P(Y=y|X=x)P(X=x).$$


Example 1: Simulation Experiment 

```{r}
P <- matrix(c(.5,.5,0,0,0,0,.25,.5,.25,0,0,0,0,.25,.5,.25,
  0,0,0,0,.25,.5,.25,0,0,0,0,.25,.5,.25,0,0,0,0,.5,.5),
         nrow=6, ncol=6, byrow = TRUE)
P
```
```{r}
s <- array(0, c(50000, 1))
# starting location for our traveler, state 3
s[1] <- 3  
# perform a loop to simulate 50,000 draws 
# from the Markov chain
for(j in 2: 50000)
    s[j] <- sample(1:6, size =1, prob = P[s[j-1],])
m <- c(500, 2000, 8000, 50000) 
res <- matrix(NA, nrow=4, ncol=6) 
for(i in 1:4)  
    res[i,] = table(s[1: m[i]])/m[i] 
colnames(res) <- 1:6 
rownames(res) <- m 
res
```

It appears from the output that the relative frequencies of the states are converging to the stationary distribution
w=(0.1,0.2,0.2,0.2,0.2,0.1)

We can confirm that w is indeed the stationary distribution of this chain by multiplying w by the transition matrix P.

```{r}
w <- c(0.1, 0.2, 0.2, 0.2, 0.2, 0.1)
w%*%P
```

It’s also possible to arrive at the stationary distribution by just multipying the transition matrix by itself over and over again until it finally converge. 

```{r}
options(digits = 4) # display  limit to four decimals
SD <- P 
for(i in 1:20) { # 20-step transition matrix
  SD <- SD %*% P
}
print(SD)
```

```{r}
# no convergence yet
for(i in 1:200) { # 220-step transition matrix
  SD <- SD %*% P
}
print(SD)
```

You’ll note that you have a 6 by 6 matrix with all rows equal. This tells you that the n-step transition matrix has converged. 

Your turn! Seatwork..

Given a Markov chain with the following transition matrix: 


$$
0.6 & 0.1 & 0.3  
0.1 & 0.7 & 0.2  
0.2 & 0.2 & 0.6
$$


Verify that the above Markov chian is irreducible and aperiodic.

Find the stationary distribution of the above Markov chain. 
https://www.probabilitycourse.com/chapter1/1_4_2_total_probability.php 
http://statisticalrecipes.blogspot.com/2013/01/easy-introduction-to-markov-chains-in-r.html 
https://github.com/clayford/ResamplingMethods 
https://willhipson.netlify.app/post/markov-sim/markov_chain/ 

https://rpubs.com/nishpan/ 


https://rpubs.com/JanpuHou/326048 

##Markov Chain Forecast Example 















https://www.machinegurning.com/rstats/bayes_r/  
https://www.machinegurning.com/rstats/markov_chain_discrete/ 






